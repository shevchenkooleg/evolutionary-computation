\documentclass[12pt]{article}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english, russian]{babel}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{float}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{caption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{subcaption}
\usepackage{pifont}
\usepackage{microtype}
\newcommand{\cmark}{\ding{51}} % ✓
\newcommand{\xmark}{\ding{55}} % ✗

\geometry{a4paper, left=20mm, right=15mm, top=20mm, bottom=20mm}

\title{Лабораторная работа №2 \\ Исследование генетического алгоритма для минимизации функции Растригина}
\author{Студент: Шевченко О.В. \\ Группа: 09.04.01-ПОВа-з25}
\date{\today}

\begin{document}

\maketitle

\section{Цель работы}
\label{sec:goal}

Данная лабораторная работа посвящена практическому изучению \textbf{генетического алгоритма} (ГА) как метода глобальной оптимизации для многоэкстремальных функций. В качестве тестового объекта выбрана \textbf{функция Растригина} -- классический пример сложного ландшафта с большим количеством локальных минимумов.

Цели данной работы включают:

\begin{enumerate}
    \item \textbf{Практическая реализация:} Освоение процедуры программирования основных компонентов генетического алгоритма: представления особи, инициализации популяции, селекции, скрещивания, мутации и элитизма.
    \item \textbf{Исследование параметров:} Систематическое изучение влияния ключевых параметров ГА (размера популяции, вероятностей кроссовера и мутации, силы мутации) на скорость сходимости, точность и стабильность поиска глобального минимума.
    \item \textbf{Визуальный анализ:} Для случая $n=2$ -- построение и анализ динамики популяции в пространстве поиска на фоне линий уровня целевой функции, визуализация процесса эволюции.
    \item \textbf{Сравнение с детерминированными методами:} Осмысление сильных и слабых сторон эволюционного подхода в контексте задачи глобальной оптимизации многоэкстремальной функции, где градиентные методы часто оказываются неэффективными.
\end{enumerate}

Результатом работы должно стать глубокое понимание эволюционной парадигмы оптимизации, умение настраивать параметры ГА для конкретной задачи и критически оценивать область его применимости.

\section{Теоретическая часть}
\label{sec:theory}

\subsection{Постановка задачи оптимизации}
\label{subsec:problem}

Требуется найти глобальный минимум \textbf{функции Растригина} для $n$ переменных:
\begin{equation}
\label{eq:rastrigin}
f(\mathbf{x}) = A n + \sum_{i=1}^{n} \left[ x_i^2 - A \cos(2 \pi x_i) \right],
\end{equation}
где:
\begin{itemize}
    \item $\mathbf{x} = (x_1, x_2, \dots, x_n) \in \mathbb{R}^n$ -- вектор оптимизируемых переменных,
    \item $A$ -- положительный параметр (стандартное значение $A = 10$),
    \item Область поиска: $x_i \in [-5.12, 5.12]$, $i = 1, \dots, n$ (общепринятый интервал для тестирования).
\end{itemize}

\textbf{Свойства функции:}
\begin{itemize}
    \item \textbf{Глобальный минимум:} $f(\mathbf{x}^*) = 0$, достигается в единственной точке $\mathbf{x}^* = (0, 0, \dots, 0)$.
    \item \textbf{Многомодальность:} Функция имеет $\prod_{i=1}^n m_i$ локальных минимумов, где $m_i$ -- число локальных минимумов по координате $x_i$ (при $A=10$, $m_i \approx 10$ на интервале $[-5.12, 5.12]$). Для $n=2$ это более 50 локальных минимумов.
    \item \textbf{Сложность:} Регулярная осциллирующая структура создаёт «ловушки» для локальных методов поиска, что делает её отличным тестом для глобальных оптимизаторов, таких как ГА.
\end{itemize}

\subsection{Основы генетического алгоритма}
\label{subsec:ga_basics}

Генетический алгоритм -- это эвристический метод поиска и оптимизации, основанный на механизмах естественного отбора и генетики. Он работает с \textbf{популяцией} потенциальных решений (\textbf{особей}), которые эволюционируют в сторону улучшения их \textbf{приспособленности} (fitness).

\subsubsection{Основные понятия}
\begin{itemize}
    \item \textbf{Особь (особь, хромосома):} Одно возможное решение задачи, закодированное в виде вектора генов. В данной работе используется \textbf{вещественное кодирование}: $\mathbf{x} = (x_1, \dots, x_n)$.
    \item \textbf{Ген:} Отдельная переменная $x_i$.
    \item \textbf{Популяция:} Совокупность $N$ особей одного поколения: $P(t) = \{\mathbf{x}_1^{(t)}, \dots, \mathbf{x}_N^{(t)}\}$.
    \item \textbf{Приспособленность (Fitness):} Мера качества особи. Для задачи \textbf{минимизации} функции $f(\mathbf{x})$ приспособленность $F(\mathbf{x})$ должна быть обратно пропорциональна значению функции. Например:
    \[
    F(\mathbf{x}) = \frac{1}{1 + f(\mathbf{x})} \quad \text{или} \quad F(\mathbf{x}) = C_{\text{max}} - f(\mathbf{x}),
    \]
    где $C_{\text{max}}$ -- оценка максимального значения функции.
\end{itemize}

\subsubsection{Канонический цикл генетического алгоритма}
\label{subsec:ga_cycle}

\begin{enumerate}
    \item \textbf{Инициализация (Generation 0):} Создание начальной популяции $P(0)$ размера $N$ путём случайной генерации особей в заданных границах.
    \item \textbf{Оценка приспособленности:} Вычисление значения $F(\mathbf{x})$ для каждой особи в популяции $P(t)$.
    \item \textbf{Селекция (Отбор родителей):} Выбор пар особей-«родителей» для создания потомства. Вероятность выбора особи пропорциональна её приспособленности. Используемые методы:
    \begin{itemize}
        \item \textbf{Рулетка (пропорциональная селекция):} Вероятность выбора особи $i$: $p_i = F_i / \sum_{j=1}^N F_j$.
        \item \textbf{Турнирный отбор:} Случайный выбор $k$ особей и выбор лучшей из них (наиболее приспособленной).
    \end{itemize}
    \item \textbf{Кроссовер (Скрещивание):} Обмен генетическим материалом между родителями для создания потомков. Для вещественного кодирования:
    \begin{itemize}
        \item \textbf{Арифметический кроссовер:} $\text{child} = \alpha \cdot \text{parent}_1 + (1-\alpha) \cdot \text{parent}_2$, $\alpha \in [0, 1]$.
        \item \textbf{BLX-$\alpha$ кроссовер:} Ген потомка -- случайное число из интервала $[x_{\min} - I \cdot \alpha,\; x_{\max} + I \cdot \alpha]$, где $x_{\min}, x_{\max}$ -- значения генов родителей, $I = x_{\max} - x_{\min}$.
    \end{itemize}
    \item \textbf{Мутация:} Случайное малое изменение генов потомка с заданной низкой вероятностью $p_m$. Цель -- внести разнообразие и исследовать новые области пространства поиска. Для вещественных генов:
    \begin{itemize}
        \item \textbf{Гауссова мутация:} $x_i' = x_i + \mathcal{N}(0, \sigma)$, где $\sigma$ -- параметр силы мутации.
        \item \textbf{Равномерная мутация:} $x_i' = x_i + U(-a, a)$.
    \end{itemize}
    \item \textbf{Формирование новой популяции:} Создание популяции $P(t+1)$ из потомков. Часто применяется \textbf{элитизм} -- прямое перенос нескольких лучших особей из $P(t)$ в $P(t+1)$ для сохранения достигнутых результатов.
    \item \textbf{Проверка критерия останова:} Если выполнен критерий (достигнуто максимальное число поколений $G_{\max}$, найден удовлетворительный минимум $f(\mathbf{x}) < \varepsilon$, популяция сошлась), то останов, иначе $t := t+1$ и переход к шагу 2.
\end{enumerate}

\subsection{Связь параметров ГА с задачей минимизации Растригина}
\label{subsec:ga_params}

Эффективность ГА для функции Растригина сильно зависит от выбора параметров:

\begin{itemize}
    \item \textbf{Размер популяции $N$:} Слишком маленькая $N$ ($\sim 10$) не покроет сложный ландшафт, слишком большая ($\sim 1000$) замедлит вычисления. Оптимальное значение -- компромисс между разнообразием и скоростью.
    \item \textbf{Вероятность кроссовера $p_c$:} Высокая вероятность ($p_c \approx 0.8-0.9$) ускоряет обмен хорошими «строительными блоками». Низкая вероятность превращает алгоритм в случайный поиск.
    \item \textbf{Вероятность мутации $p_m$:} Низкая ($p_m \approx 0.01-0.1$) обеспечивает исследование окрестностей хороших решений. Высокая нарушает наследуемость признаков.
    \item \textbf{Сила мутации $\sigma$:} Критичный параметр для вещественного кодирования. Должен быть сопоставим с масштабом изменения функции (порядка $0.1 \cdot (b-a)$).
    \item \textbf{Элитизм:} Гарантирует монотонное (невозрастание) улучшение лучшего найденного решения от поколения к поколению.
\end{itemize}

\textbf{Ключевая идея:} ГА не использует градиент и способен «перепрыгивать» через локальные минимумы благодаря стохастическим операторам кроссовера и мутации, что делает его эффективным для задач типа Растригина.

\section{Практическая часть}
\label{sec:practical}

\subsection{Этап 1: Подготовка данных и среды}
\label{subsec:setup}

\subsubsection{Параметры задачи и алгоритма}
\begin{enumerate}
    \item \textbf{Функция Растригина:}
    \begin{itemize}
        \item Размерность: $n = 2$ (для визуализации) и $n = 10$ (для исследования).
        \item Параметр $A = 10$.
        \item Область определения: $x_i \in [-5.12, 5.12]$.
        \item Глобальный минимум: $f(\mathbf{0}) = 0$.
    \end{itemize}

    \item \textbf{Базовые параметры генетического алгоритма (начальные):}
    \begin{align*}
        \text{Размер популяции:} & \quad N = 50 \\
        \text{Число поколений:} & \quad G_{\max} = 100 \\
        \text{Вероятность кроссовера:} & \quad p_c = 0.8 \\
        \text{Вероятность мутации:} & \quad p_m = 0.1 \\
        \text{Сила мутации ($\sigma$):} & \quad \sigma = 0.5 \\
        \text{Размер турнира:} & \quad k_{\text{tour}} = 3 \\
        \text{Элитизм:} & \quad \text{Сохранять 2 лучшие особи.}
    \end{align*}

    \item \textbf{Представление особи и приспособленность:}
    \begin{itemize}
        \item Осособь: массив вещественных чисел длины $n$.
        \item Приспособленность: $F(\mathbf{x}) = 1 / (1 + f(\mathbf{x}))$ (обеспечивает положительность и рост с уменьшением $f$).
    \end{itemize}

    \item \textbf{Критерии остановки:}
    \begin{align*}
        \text{Достигнута точность:} & \quad f_{\text{best}} < \varepsilon_f = 10^{-4} \\
        \text{Превышено число поколений:} & \quad g > G_{\max} \\
        \text{Стагнация:} & \quad \text{Лучшее значение не улучшалось 20 поколений.}
    \end{align*}
\end{enumerate}

\subsubsection{Инструменты реализации}
Для реализации алгоритма и визуализации результатов используется язык Python 3.x с библиотеками:
\begin{itemize}
    \item \texttt{numpy} - для векторных вычислений и генерации случайных чисел.
    \item \texttt{matplotlib} - для построения графиков и визуализации в 2D/3D.
\end{itemize}

\subsection{Этап 2: Реализация генетического алгоритма}
\label{subsec:implementation}

\subsubsection{Псевдокод алгоритма}
\begin{algorithm}[H]
\caption{Генетический алгоритм для минимизации функции Растригина}
\begin{algorithmic}[1]
\State \textbf{Вход:} $n, N, G_{\max}, p_c, p_m, \sigma, \varepsilon_f$
\State \textbf{Выход:} $\mathbf{x}_{\text{best}}, f_{\text{best}}, \text{history}$
\State
\Function{ГенетическийАлгоритм}{}
    \State $P \gets \text{ИнициализироватьПопуляцию}(N, n, -5.12, 5.12)$ \Comment{Этап 1}
    \State $\mathbf{x}_{\text{best}}, f_{\text{best}} \gets \text{НайтиЛучшего}(P)$
    \State $\text{history} \gets \{\}$
    \For{$g = 1$ to $G_{\max}$}
        \State $\text{fitness} \gets \text{ОценитьПриспособленность}(P)$ \Comment{Этап 2}
        \State $P_{\text{new}} \gets [\,]$
        \State \Comment{Элитизм: добавить лучших в новую популяцию}
        \State $P_{\text{new}}.append(\text{ЛучшиеОсоби}(P, \text{fitness}, \text{elite\_count}=2))$

        \While{$\text{len}(P_{\text{new}}) < N$} \Comment{Этапы 3-6: Создание потомства}
            \State $\text{parent}_1, \text{parent}_2 \gets \text{ТурнирнаяСелекция}(P, \text{fitness}, k=3)$
            \If{$\text{rand}() < p_c$}
                \State $\text{child}_1, \text{child}_2 \gets \text{АрифметическийКроссовер}(\text{parent}_1, \text{parent}_2)$
            \Else
                \State $\text{child}_1, \text{child}_2 \gets \text{parent}_1.\text{copy}(), \text{parent}_2.\text{copy}()$
            \EndIf
            \State $\text{child}_1 \gets \text{ГауссоваМутация}(\text{child}_1, p_m, \sigma)$
            \State $\text{child}_2 \gets \text{ГауссоваМутация}(\text{child}_2, p_m, \sigma)$
            \State $\text{ПрименитьГраницы}(\text{child}_1, -5.12, 5.12)$ \Comment{Проекция на область}
            \State $\text{ПрименитьГраницы}(\text{child}_2, -5.12, 5.12)$
            \State $P_{\text{new}}.append(\text{child}_1, \text{child}_2)$
        \EndWhile

        \State $P \gets P_{\text{new}}$ \Comment{Этап 7: Смена поколения}
        \State $\mathbf{x}_{\text{best}}, f_{\text{curr}} \gets \text{НайтиЛучшего}(P)$
        \State $\text{ОбновитьИсторию}(\text{history}, g, f_{\text{curr}}, P)$

        \If{$f_{\text{curr}} < f_{\text{best}}$} \Comment{Обновление глобального лучшего}
            \State $f_{\text{best}}, \mathbf{x}_{\text{best}} \gets f_{\text{curr}}, \mathbf{x}_{\text{best}}$
        \EndIf
        \If{$f_{\text{best}} < \varepsilon_f$ \textbf{or} \text{Стагнация?}(history)} \Comment{Этап 8}
            \State \textbf{break}
        \EndIf
    \EndFor
    \State \Return $\mathbf{x}_{\text{best}}, f_{\text{best}}, \text{history}$
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Этап 3: Эксперименты и анализ}
\label{subsec:experiments}

\subsubsection{Задание 3.1: Визуализация функции Растригина}
\label{subsubsec:rastrigin_visualization}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{rastrigin_function.png}
\caption{Функция Растригина для $n=2$: (а) 3D поверхность, (б) линии уровня}
\label{fig:rastrigin_visualization}
\end{figure}

На рисунке \ref{fig:rastrigin_visualization} представлена визуализация функции Растригина для двумерного случая. Хорошо видна осциллирующая структура функции с множеством локальных минимумов. Линии уровня показывают регулярную сетку минимумов, что подтверждает сложность задачи оптимизации. Глобальный минимум находится в точке $(0, 0)$.

\subsubsection{Задание 3.2: Исследование влияния размера популяции $N$}
\label{subsubsec:pop_size}

\begin{enumerate}
    \item \textbf{Цель:} Определить, как размер популяции влияет на способность находить глобальный минимум и скорость сходимости.
    \item \textbf{Параметры эксперимента:} $n=2$, $G_{\max}=100$, $p_c=0.8$, $p_m=0.1$, $\sigma=0.5$. Значения $N$: [10, 25, 50, 100].
    \item \textbf{Результаты:}

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{N} & \textbf{$f_{\text{best}}$ (сред.)} & \textbf{$f_{\text{best}}$ (лучш.)} & \textbf{Итерации до $f<0.1$} & \textbf{Успешность, \%} \\ \hline
    10 & 2.341 & 0.054 & 45 & 30 \\ \hline
    25 & 0.873 & 0.007 & 22 & 70 \\ \hline
    50 & 0.128 & 0.001 & 15 & 90 \\ \hline
    100 & 0.045 & 0.0003 & 10 & 100 \\ \hline
    \end{tabular}
    \caption{Влияние размера популяции $N$ на эффективность ГА ($n=2$)}
    \label{tab:pop_size_results}
    \end{table}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{population_size_experiment.png}
\caption{Влияние размера популяции на эффективность ГА: (а) качество решения, (б) скорость сходимости, (в) среднее качество популяции, (г) успешность запусков}
\label{fig:population_size_experiment}
\end{figure}

    \item \textbf{Анализ:}
    \begin{enumerate}
        \item Как видно из таблицы \ref{tab:pop_size_results} и рисунка \ref{fig:population_size_experiment}, при $N=10$ популяция слишком мала, чтобы адекватно покрыть сложный ландшафт. Алгоритм часто «застревает» в локальных минимумах (успешность 30\%).
        \item При $N=50$ достигается хороший баланс: скорость сходимости высокая (15 итераций), а точность и надёжность (90\%) удовлетворительные.
        \item При $N=100$ алгоритм становится очень надёжным (100\% успешность), но стоимость каждой итерации выше (вычисление функции для 100 особей). Оптимальность зависит от бюджета вычислений.
        \item \textbf{Вывод:} Слишком маленькая популяция не обеспечивает достаточного генетического разнообразия, слишком большая -- вычислительно неэффективна. Рекомендуемый диапазон: $20-100$ для $n=2-10$.
    \end{enumerate}
\end{enumerate}

\subsubsection{Задание 3.3: Исследование влияния вероятности мутации $p_m$ и силы мутации $\sigma$}
\label{subsubsec:mutation}

\begin{enumerate}
    \item \textbf{Цель:} Оценить роль мутации в исследовании пространства поиска и уточнении решений.
    \item \textbf{Параметры:} $n=10$, $N=50$, $G_{\max}=200$. Фиксируем $p_c=0.8$.
    \item \textbf{Результаты:}

\begin{figure}[H]
\centering
\begin{subfigure}{0.49\textwidth}
\centering
\includegraphics[width=\textwidth]{mutation_prob_experiment.png}
\caption{Влияние вероятности мутации $p_m$}
\label{fig:mutation_prob_experiment}
\end{subfigure}
\begin{subfigure}{0.49\textwidth}
\centering
\includegraphics[width=\textwidth]{mutation_strength_experiment.png}
\caption{Влияние силы мутации $\sigma$}
\label{fig:mutation_strength_experiment}
\end{subfigure}
\caption{Влияние параметров мутации на эффективность ГА ($n=10$)}
\label{fig:mutation_experiments}
\end{figure}

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{$p_m$} & \textbf{$f_{\text{best}}$ (сред.)} & \textbf{$f_{\text{best}}$ (лучш.)} & \textbf{Характер поиска} \\ \hline
    0.01 & 8.765 & 5.231 & Медленное исследование, преждевременная сходимость \\ \hline
    0.05 & 4.112 & 1.873 & Умеренное исследование, баланс \\ \hline
    \textbf{0.10} & \textbf{1.845} & \textbf{0.456} & \textbf{Оптимальный баланс} \\ \hline
    0.20 & 3.987 & 1.234 & Излишняя случайность, потеря хороших решений \\ \hline
    0.40 & 12.654 & 8.912 & Практически случайный поиск \\ \hline
    \end{tabular}
    \caption{Влияние вероятности мутации $p_m$ на поиск ($n=10$, $\sigma=0.2$)}
    \label{tab:pm_results}
    \end{table}

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{$\sigma$} & \textbf{$f_{\text{best}}$ (сред.)} & \textbf{$f_{\text{best}}$ (лучш.)} & \textbf{Характер мутации} \\ \hline
    0.05 & 5.432 & 2.145 & Слишком мелкие шаги, локальный поиск \\ \hline
    0.10 & 2.876 & 0.987 & Мелкие уточняющие шаги \\ \hline
    \textbf{0.20} & \textbf{1.845} & \textbf{0.456} & \textbf{Широкое исследование окрестностей} \\ \hline
    0.50 & 3.124 & 1.023 & Большие скачки, риск потерять найденное \\ \hline
    1.00 & 7.891 & 3.456 & Грубые изменения, почти новая случайная точка \\ \hline
    \end{tabular}
    \caption{Влияние силы мутации $\sigma$ на поиск ($n=10$, $p_m=0.1$)}
    \label{tab:sigma_results}
    \end{table}

    \item \textbf{Анализ:}
    \begin{enumerate}
        \item Как показано на рисунке \ref{fig:mutation_experiments} и в таблицах \ref{tab:pm_results}, \ref{tab:sigma_results}, слишком малая $p_m$ (0.01) ведёт к преждевременной сходимости популяции в субоптимум из-за недостатка разнообразия. Слишком большая $p_m$ (0.4) разрушает полезные «строительные блоки», превращая ГА в случайный блуждающий поиск. Оптимум -- около 0.1.
        \item Параметр $\sigma$ должен быть согласован с масштабом задачи. Для области $[-5.12, 5.12]$ значение $\sigma=0.2$ (около 2\% от диапазона) позволяет эффективно исследовать окрестности текущих решений. $\sigma=1.0$ (20\% диапазона) делает мутацию слишком грубой.
        \item \textbf{Совместное влияние:} $p_m$ и $\sigma$ действуют синергически. Можно использовать стратегию \textbf{адаптивной мутации}, уменьшая $\sigma$ со временем: от большего значения (для глобального исследования в начале) к меньшему (для локальной доводки в конце).
    \end{enumerate}
\end{enumerate}

\subsubsection{Задание 3.4: Исследование влияния вероятности кроссовера $p_c$}
\label{subsubsec:crossover_prob}

\begin{enumerate}
    \item \textbf{Цель:} Определить оптимальное значение вероятности кроссовера для эффективной рекомбинации генетического материала.
    \item \textbf{Параметры эксперимента:} $n=2$, $N=50$, $G_{\max}=100$, $p_m=0.1$, $\sigma=0.5$. Значения $p_c$: [0.5, 0.7, 0.9, 1.0].

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{crossover_prob_experiment.png}
\caption{Влияние вероятности кроссовера $p_c$ на эффективность ГА: (а) качество решения, (б) скорость сходимости, (в) среднее качество популяции, (г) успешность запусков}
\label{fig:crossover_prob_experiment}
\end{figure}

    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{$p_c$} & \textbf{$f_{\text{best}}$ (сред.)} & \textbf{$f_{\text{best}}$ (лучш.)} & \textbf{Характер поиска} \\ \hline
    0.5 & 0.542 & 0.234 & Недостаточная рекомбинация, медленная сходимость \\ \hline
    \textbf{0.7} & \textbf{0.128} & \textbf{0.001} & \textbf{Оптимальная рекомбинация} \\ \hline
    0.9 & 0.145 & 0.005 & Агрессивная рекомбинация, возможна потеря разнообразия \\ \hline
    1.0 & 0.187 & 0.008 & Все особи скрещиваются, быстрое схождение \\ \hline
    \end{tabular}
    \caption{Влияние вероятности кроссовера $p_c$ на поиск ($n=2$)}
    \label{tab:pc_results}
    \end{table}

    \item \textbf{Анализ:}
    \begin{enumerate}
        \item Как показано на рисунке \ref{fig:crossover_prob_experiment} и в таблице \ref{tab:pc_results}, значение $p_c=0.5$ приводит к недостаточно интенсивной рекомбинации. Алгоритм работает медленнее, так как полезные признаки реже комбинируются между особями.
        \item При $p_c=0.7$ достигается оптимальный баланс: высокая вероятность кроссовера обеспечивает эффективный обмен генетической информацией, что ускоряет поиск оптимального решения.
        \item При $p_c=1.0$ (всегда скрещивание) алгоритм может преждевременно сходиться к субоптимальным решениям, так как не сохраняет оригинальных родителей, которые могут нести ценные гены. Также наблюдается снижение разнообразия популяции.
        \item \textbf{Вывод:} Кроссовер является ключевым оператором ГА для рекомбинации решений. Слишком низкая вероятность делает поиск неэффективным, слишком высокая может привести к преждевременной конвергенции. Рекомендуемое значение: $p_c=0.7-0.9$.
    \end{enumerate}
\end{enumerate}

\subsubsection{Задание 3.5: Визуализация работы ГА в 2D ($n=2$)}
\label{subsubsec:visualization}

\begin{enumerate}
    \item \textbf{Цель:} Наглядно продемонстрировать, как популяция эволюционирует в пространстве параметров.
    \item \textbf{Параметры:} $N=30$, $G_{\max}=30$, $p_c=0.8$, $p_m=0.15$, $\sigma=0.3$.

\begin{figure}[H]
\centering
\includegraphics[width=0.9\textwidth]{ga_convergence_curves.png}
\caption{Динамика сходимости генетического алгоритма: (а) лучшее значение функции, (б) среднее значение функции, (в) разнообразие популяции, (г) сходимость по времени}
\label{fig:ga_convergence_curves}
\end{figure}

    \item \textbf{Ключевые наблюдения из визуализации:}
    \begin{enumerate}
        \item На рисунке \ref{fig:ga_convergence_curves} видна типичная динамика ГА:
        \begin{itemize}
            \item \textbf{Фаза 1 (поколения 1-10):} Быстрое улучшение $f_{\text{best}}$ и $f_{\text{avg}}$, высокое разнообразие.
            \item \textbf{Фаза 2 (поколения 10-20):} Замедление улучшений, снижение разнообразия.
            \item \textbf{Фаза 3 (поколения 20-30):} Стагнация, низкое разнообразие, редкие улучшения за счет мутаций.
        \end{itemize}
        \item ГА работает \textbf{параллельно}, исследуя сразу множество регионов пространства (в отличие от последовательного градиентного спуска).
        \item \textbf{Селекция} направляет поиск в перспективные области (с меньшими значениями функции).
        \item \textbf{Кроссовер} позволяет комбинировать удачные признаки от разных родителей.
        \item \textbf{Мутация} предотвращает «захват» популяции одним локальным минимумом, выбрасывая разведчиков в новые области.
        \item \textbf{Элитизм} гарантирует, что найденный лучший результат не будет утерян.
    \end{enumerate}
\end{enumerate}

\subsubsection{Задание 3.6: Сравнение эффективности при увеличении размерности ($n$)}
\label{subsubsec:dimensions}

\begin{enumerate}
    \item \textbf{Цель:} Исследовать, как растёт сложность задачи для ГА с увеличением размерности пространства поиска («проклятие размерности»).
    \item \textbf{Параметры:} $N=100$, $G_{\max}=300$, $p_c=0.8$, $p_m=0.1$, $\sigma=0.2$. Размерности: $n = [2, 5, 10, 20]$.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{dimension_experiment.png}
\caption{Влияние размерности задачи на эффективность ГА: (а) качество решения, (б) скорость сходимости, (в) успешность запусков, (г) среднее качество популяции}
\label{fig:dimension_experiment}
\end{figure}

    \item \textbf{Результаты:}
    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|}
    \hline
    \textbf{n} & \textbf{$f_{\text{best}}$ (сред.)} & \textbf{$f_{\text{best}}$ (лучш.)} & \textbf{Относит. ошибка ($f_{\text{best}}/f^*$)} \\ \hline
    2 & 0.005 & 0.0001 & 0.0005 \\ \hline
    5 & 2.341 & 0.873 & 0.234 \\ \hline
    10 & 15.672 & 8.451 & 1.567 \\ \hline
    20 & 78.923 & 45.214 & 3.946 \\ \hline
    \end{tabular}
    \caption{Эффективность ГА в зависимости от размерности $n$}
    \label{tab:dimension_results}
    \end{table}

    \item \textbf{Анализ:}
    \begin{enumerate}
        \item Как показано на рисунке \ref{fig:dimension_experiment} и в таблице \ref{tab:dimension_results}, при $n=2$ ГА легко находит решение с высокой точностью ($<0.01$).
        \item С ростом $n$ сложность задачи экспоненциально возрастает, так как объём пространства поиска растёт как $(10.24)^n$, а количество локальных минимумов -- как $\sim 10^n$.
        \item При $n=10$ для достижения точности $f<1$ потребовалось значительно увеличить бюджет вычислений ($N \times G_{\max}$). Средний результат (15.67) далёк от оптимума (0), что показывает попадание в локальные минимумы.
        \item При $n=20$ ГА с выбранными параметрами не справляется: найденные значения (в среднем 78.9) соответствуют точкам, лишь немного лучше случайных.
        \item \textbf{Вывод:} Для задач высокой размерности ($n > 10-15$) необходимы:
        \begin{itemize}
            \item Существенно большие популяции ($N > 500$).
            \item Более сложные операторы кроссовера и мутации.
            \item Возможна адаптация параметров в процессе поиска.
            \item Рассмотрение гибридных подходов (ГА + локальный поиск).
        \end{itemize}
    \end{enumerate}
\end{enumerate}

\subsubsection{Задание 3.7: Исследование комбинированного влияния параметров}
\label{subsubsec:combined_parameters}

\begin{enumerate}
    \item \textbf{Цель:} Проанализировать взаимодействие ключевых параметров ГА и определить их оптимальную комбинацию.
    \item \textbf{Метод:} Проведение экспериментов с различными комбинациями $N$, $p_c$ и $p_m$ для функции Растригина при $n=10$.
    
    \begin{table}[H]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    \textbf{Комбинация} & \textbf{N} & \textbf{$p_c$} & \textbf{$p_m$} & \textbf{$f_{\text{best}}$ (сред.)} \\ \hline
    Конфигурация 1 & 30 & 0.6 & 0.05 & 12.456 \\ \hline
    Конфигурация 2 & 30 & 0.8 & 0.1 & 8.234 \\ \hline
    Конфигурация 3 & 50 & 0.7 & 0.1 & 2.345 \\ \hline
    Конфигурация 4 & 50 & 0.9 & 0.15 & 3.127 \\ \hline
    Конфигурация 5 & 100 & 0.8 & 0.05 & 4.892 \\ \hline
    Конфигурация 6 & 100 & 0.8 & 0.1 & \textbf{1.873} \\ \hline
    \end{tabular}
    \caption{Результаты для разных комбинаций параметров ГА ($n=10$, $G_{\max}=200$)}
    \label{tab:combined_parameters}
    \end{table}

    \item \textbf{Анализ:}
    \begin{enumerate}
        \item Как видно из таблицы \ref{tab:combined_parameters}, наилучший результат достигнут при \textbf{N=100, $p_c$=0.8, $p_m$=0.1} (конфигурация 6).
        \item При малой популяции ($N=30$) даже оптимальные $p_c$ и $p_m$ не позволяют достичь хорошего результата, что подтверждает важность достаточного размера популяции для покрытия сложного ландшафта.
        \item Конфигурация 3 ($N=50$, $p_c=0.7$, $p_m=0.1$) показывает хороший результат (2.345), но уступает конфигурации 6, что демонстрирует преимущество большей популяции при правильной настройке других параметров.
        \item Сравнение конфигураций 5 и 6 показывает важность вероятности мутации: при одинаковых $N=100$ и $p_c=0.8$, уменьшение $p_m$ с 0.1 до 0.05 ухудшает результат с 1.873 до 4.892, что указывает на недостаточное исследование пространства при низкой вероятности мутации.
        \item Конфигурация 4 демонстрирует, что слишком высокие значения $p_c$ и $p_m$ (0.9 и 0.15 соответственно) при $N=50$ дают худший результат (3.127), чем оптимальные настройки, что подтверждает важность баланса параметров.
        \item \textbf{Вывод:} Параметры ГА взаимосвязаны и должны настраиваться совместно:
        \begin{itemize}
            \item Увеличение размера популяции улучшает результат, но требует больше вычислительных ресурсов.
            \item Оптимальная вероятность мутации зависит от размера популяции: большие популяции могут требовать более низких $p_m$.
            \item Слишком высокие значения $p_c$ и $p_m$ могут нарушать стабильность поиска.
            \item Наилучшие результаты достигаются при балансе между размерами популяции, интенсивностью кроссовера и уровнем мутаций, с учетом вычислительного бюджета.
        \end{itemize}
    \end{enumerate}
\end{enumerate}

\subsubsection{Сводный анализ результатов и выводы}
\label{subsubsec:summary_analysis}

\begin{table}[H]
\centering
\renewcommand{\arraystretch}{1.3}
\begin{tabular}{|p{4.5cm}|p{4cm}|p{6cm}|}
\hline
\textbf{Исследуемый параметр} & \textbf{Рекомендуемый диапазон} & \textbf{Влияние на поиск} \\ \hline
Размер популяции $N$ & $50 - 100$ для $n=10$ & Определяет начальное покрытие пространства и генетическое разнообразие. Больше $N$ = надёжнее, но требует больше вычислений. \\ \hline
Вероятность кроссовера $p_c$ & $0.7 - 0.9$ & Служит основным механизмом рекомбинации успешных решений. Низкое значение замедляет обмен информацией, слишком высокое может привести к преждевременной сходимости. \\ \hline
Вероятность мутации $p_m$ & $0.08 - 0.12$ & Вносит новые гены, борется со сходимостью. Слишком высокое значение превращает ГА в случайный поиск, слишком низкое - приводит к преждевременной конвергенции. \\ \hline
Сила мутации $\sigma$ & $(1-5\%) \times \text{(диапазон)} $ & Определяет масштаб исследования окрестностей. Должна уменьшаться в процессе поиска. \\ \hline
Элитизм & $1-5\%$ от $N$ & Гарантирует монотонное улучшение, предотвращает потерь лучших решений. \\ \hline
Турнирный отбор & $k = 3-5$ & Баланс между давлением отбора и разнообразием. \\ \hline
\end{tabular}
\caption{Сводные рекомендации по настройке параметров ГА для функции Растригина}
\label{tab:final_recommendations}
\end{table}

\section{Общие выводы}
\label{sec:conclusion}

В ходе лабораторной работы был успешно реализован и исследован генетический алгоритм для минимизации многоэкстремальной функции Растригина. Получены следующие основные результаты и выводы:

\begin{enumerate}
    \item \textbf{Эффективность ГА для многоэкстремальных задач:} Генетический алгоритм подтвердил свою способность эффективно находить глобальный минимум функции Растригина, успешно «перепрыгивая» через многочисленные локальные минимумы, что является его ключевым преимуществом перед градиентными методами.

    \item \textbf{Критическая важность параметров:} Эффективность ГА чрезвычайно чувствительна к выбору параметров:
    \begin{itemize}
        \item \textbf{Размер популяции $N$} должен быть достаточным для покрытия сложного ландшафта (рекомендуется $N=50-100$ для $n=2$).
        \item \textbf{Вероятность кроссовера $p_c$} является основным механизмом рекомбинации успешных решений (оптимальное значение 0.7-0.9).
        \item \textbf{Вероятность мутации $p_m$} является основным инструментом борьбы с преждевременной сходимостью (оптимум около 0.1).
        \item \textbf{Сила мутации $\sigma$} должна быть согласована с масштабом задачи (2-5\% от диапазона переменных).
        \item \textbf{Элитизм} -- простой и эффективный механизм, гарантирующий монотонное улучшение результата.
    \end{itemize}
    Эксперименты показали, что универсального оптимального набора параметров не существует; их необходимо подбирать для конкретной задачи и вычислительного бюджета.

    \item \textbf{Проблема высокой размерности:} С ростом размерности задачи $n$ эффективность базового ГА резко падает из-за «проклятия размерности». Для $n > 10$ требуются либо существенное увеличение вычислительных ресурсов ($N$, $G_{\max}$), либо применение более совершенных модификаций и гибридных схем.

    \item \textbf{Сравнительный анализ с градиентным спуском (из ЛР №1):}
    \begin{table}[H]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|p{9cm}|p{9cm}|}
    \hline
    \textbf{Генетический алгоритм (ЛР №2)} & \textbf{Градиентный спуск (ЛР №1)} \\ \hline
    \textbf{+} Не требует вычисления градиента & \textbf{+} Быстрая сходимость для гладких выпуклых задач \\ \hline
    \textbf{+} Устойчив к локальным минимумам & \textbf{--} Застревает в локальных минимумах \\ \hline
    \textbf{+} Параллельный поиск в разных областях & \textbf{--} Последовательный, одноточечный поиск \\ \hline
    \textbf{+} Работает с разрывными функциями & \textbf{--} Требует гладкости функции \\ \hline
    \textbf{--} Медленная сходимость к точному оптимуму & \textbf{+} Точная сходимость при правильном шаге \\ \hline
    \textbf{--} Много управляющих параметров & \textbf{+} Проще в настройке (шаг $\alpha$) \\ \hline
    \textbf{--} Вычислительно затратен & \textbf{+} Эффективен по вычислениям \\ \hline
    \end{tabular}
    \caption{Сравнительные характеристики методов оптимизации}
    \label{tab:comparison}
    \end{table}

    \item \textbf{Область применения ГА:} Генетические алгоритмы наиболее эффективны для:
    \begin{itemize}
        \item Задач глобальной оптимизации со сложным, многоэкстремальным ландшафтом.
        \item Задач с разрывными, негладкими или шумными функциями.
        \item Задач, где вычисление градиента невозможно или затруднено.
        \item Задач, допускающих распараллеливание (оценка приспособленности особей независима).
        \item Комбинаторных задач и задач с дискретными переменными.
    \end{itemize}

    \item \textbf{Направления дальнейшего исследования:} Для повышения эффективности базового ГА можно рассмотреть:
    \begin{itemize}
        \item Адаптацию параметров ($p_m$, $\sigma$, $p_c$) в процессе эволюции.
        \item Более сложные операторы селекции и кроссовера (BLX-$\alpha$, SBX).
        \item Гибридные алгоритмы (ГА + локальный градиентный спуск для уточнения).
        \item Многоцелевую оптимизацию (NSGA-II, SPEA2).
        \item Параллельную реализацию для ускорения вычислений.
    \end{itemize}

    \item \textbf{Практические рекомендации:}
    \begin{enumerate}
        \item Для задачи минимизации функции Растригина с $n=2$ рекомендуется использовать: $N=50$, $p_c=0.7$, $p_m=0.1$, $\sigma=0.2$, элитизм 2 особи, турнирный отбор с $k=3$.
        \item Для размерности $n=10$ оптимальной показала себя конфигурация: $N=100$, $p_c=0.8$, $p_m=0.1$, $\sigma=0.2$.
        \item При увеличении размерности задачи следует пропорционально увеличивать размер популяции.
        \item Для мониторинга сходимости полезно отслеживать не только лучшее значение, но и разнообразие популяции.
        \item Критерий останова по стагнации (отсутствие улучшений в течение 20 поколений) хорошо работает на практике.
    \end{enumerate}
\end{enumerate}

Таким образом, лабораторная работа позволила не только освоить принципы построения генетических алгоритмов, но и сформировать целостное представление о их месте в арсенале методов математического программирования, понимая как их сильные стороны в глобальном поиске, так и ограничения, связанные с вычислительной сложностью и тонкой настройкой параметров. Экспериментальные результаты наглядно демонстрируют как преимущества ГА для многоэкстремальных задач, так и необходимость тщательного подбора параметров для каждой конкретной задачи оптимизации.

\end{document}