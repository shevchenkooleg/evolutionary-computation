#!/usr/bin/env python3
"""
–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º PSO –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ Iris.
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
from typing import Dict, Any, List, Tuple
import json
import time
import os
from datetime import datetime

from neural_network import NeuralNetwork
from pso_neural_network import ModifiedPSO


def create_results_directory():
    """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_dir = f"results_{timestamp}"
    os.makedirs(results_dir, exist_ok=True)
    return results_dir


def run_pso_experiment(results_dir: str = "results"):
    """–û—Å–Ω–æ–≤–Ω–æ–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å PSO"""
    print("=" * 70)
    print("–≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢: –û–±—É—á–µ–Ω–∏–µ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ PSO")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print("\nüìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö Iris...")
    data = NeuralNetwork.load_iris_data(test_size=0.3, random_state=42)

    print(f"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏: {data['X_train'].shape}")
    print(f"–†–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏: {data['X_test'].shape}")

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞
    nn_architecture = {
        'input_size': 4,
        'hidden_size': 8,
        'output_size': 3
    }

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ PSO
    pso_params = {
        'swarm_size': 30,
        'nn_architecture': nn_architecture,
        'w': 0.7,
        'c1': 1.5,
        'c2': 1.5,
        'v_max': 0.3,
        'local_search_prob': 0.2
    }

    print("\nüìù –ü–∞—Ä–∞–º–µ—Ç—Ä—ã PSO:")
    for key, value in pso_params.items():
        print(f"  {key}: {value}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –∏ –∑–∞–ø—É—Å–∫ PSO
    print("\nüêù –ó–∞–ø—É—Å–∫ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ PSO...")
    pso = ModifiedPSO(**pso_params)

    start_time = time.time()
    results = pso.run(
        X_train=data['X_train'],
        y_train=data['y_train'],
        y_train_onehot=data['y_train_onehot'],
        X_val=data['X_test'],
        y_val=data['y_test'],
        max_iterations=100,
        early_stopping_patience=25
    )
    end_time = time.time()

    training_time = end_time - start_time
    print(f"\n‚úÖ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {training_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"–õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {results['best_accuracy']:.4f}")
    print(f"–õ—É—á—à–∏–π loss: {results['best_fitness']:.4f}")

    # –û—Ü–µ–Ω–∫–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
    best_model = results['best_model']
    test_accuracy = best_model.get_accuracy(data['X_test'], data['y_test'])
    test_predictions = best_model.predict(data['X_test'])

    print(f"\nüìà –§–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print(f"–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ: {test_accuracy:.4f}")

    # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    print("\nüìä –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫:")
    cm = confusion_matrix(data['y_test'], test_predictions)
    print("\n" + str(cm))

    # –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    print("\nüìã –û—Ç—á–µ—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:")
    target_names = ['Setosa', 'Versicolor', 'Virginica']
    report = classification_report(data['y_test'], test_predictions,
                                   target_names=target_names, output_dict=True)
    print(classification_report(data['y_test'], test_predictions,
                                target_names=target_names))

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    plot_paths = visualize_results(results, data, best_model, results_dir)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    save_path = save_results(results, pso_params, training_time, data,
                             test_accuracy, report, results_dir)

    print_results_summary(results, data, training_time, plot_paths, save_path)

    return results, data


def visualize_results(results: Dict[str, Any], data: Dict[str, Any],
                      best_model: NeuralNetwork, results_dir: str) -> Dict[str, str]:
    """–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""
    plot_paths = {}

    # –°–æ–∑–¥–∞–Ω–∏–µ —Ñ–∏–≥—É—Ä —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
    fig1, axes1 = plt.subplots(2, 2, figsize=(14, 10))
    fig1.suptitle('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ PSO',
                  fontsize=16, fontweight='bold')

    history = results['history']
    iterations = list(range(1, len(history['train_loss']) + 1))

    # –ì—Ä–∞—Ñ–∏–∫ 1: –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
    ax1 = axes1[0, 0]
    ax1.plot(iterations, history['train_loss'], 'b-', linewidth=2, label='Train Loss')
    ax1.plot(iterations, history['global_best_loss'], 'r--', linewidth=2,
             label='Global Best Loss')
    ax1.set_xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.set_title('–î–∏–Ω–∞–º–∏–∫–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å', fontsize=13)
    ax1.legend()
    ax1.grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 2: –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    ax2 = axes1[0, 1]
    ax2.plot(iterations, history['val_accuracy'], 'g-', linewidth=2)
    ax2.set_xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è', fontsize=12)
    ax2.set_ylabel('Accuracy', fontsize=12)
    ax2.set_title('–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ', fontsize=13)
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim([0, 1])
    ax2.axhline(y=0.95, color='r', linestyle='--', alpha=0.5, label='95% accuracy')
    ax2.legend()

    # –ì—Ä–∞—Ñ–∏–∫ 3: –†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–æ—è
    ax3 = axes1[1, 0]
    ax3.plot(iterations, history['swarm_diversity'], 'm-', linewidth=2)
    ax3.set_xlabel('–ò—Ç–µ—Ä–∞—Ü–∏—è', fontsize=12)
    ax3.set_ylabel('–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ', fontsize=12)
    ax3.set_title('–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ä–æ—è PSO', fontsize=13)
    ax3.grid(True, alpha=0.3)

    # –ì—Ä–∞—Ñ–∏–∫ 4: –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
    ax4 = axes1[1, 1]
    test_predictions = best_model.predict(data['X_test'])
    cm = confusion_matrix(data['y_test'], test_predictions)

    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=['Setosa', 'Versicolor', 'Virginica'],
                yticklabels=['Setosa', 'Versicolor', 'Virginica'],
                ax=ax4)
    ax4.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å', fontsize=12)
    ax4.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å', fontsize=12)
    ax4.set_title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ', fontsize=13)

    plt.tight_layout()
    fig1_path = os.path.join(results_dir, 'training_results.png')
    plt.savefig(fig1_path, dpi=300, bbox_inches='tight')
    plot_paths['training_results'] = fig1_path
    plt.close(fig1)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫: —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤
    fig2, ax5 = plt.subplots(figsize=(10, 6))
    weights_vector = best_model.get_weights_vector()
    ax5.hist(weights_vector, bins=50, alpha=0.7, edgecolor='black', color='steelblue')
    ax5.set_xlabel('–ó–Ω–∞—á–µ–Ω–∏–µ –≤–µ—Å–∞', fontsize=12)
    ax5.set_ylabel('–ß–∞—Å—Ç–æ—Ç–∞', fontsize=12)
    ax5.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –æ–±—É—á–µ–Ω–Ω–æ–π —Å–µ—Ç–∏', fontsize=14)
    ax5.grid(True, alpha=0.3)

    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    stats_text = f"–ú–∏–Ω–∏–º—É–º: {weights_vector.min():.3f}\n" \
                 f"–ú–∞–∫—Å–∏–º—É–º: {weights_vector.max():.3f}\n" \
                 f"–°—Ä–µ–¥–Ω–µ–µ: {weights_vector.mean():.3f}\n" \
                 f"–°—Ç. –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {weights_vector.std():.3f}"
    ax5.text(0.95, 0.95, stats_text, transform=ax5.transAxes,
             verticalalignment='top', horizontalalignment='right',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()
    fig2_path = os.path.join(results_dir, 'weights_distribution.png')
    plt.savefig(fig2_path, dpi=300, bbox_inches='tight')
    plot_paths['weights_distribution'] = fig2_path
    plt.close(fig2)

    return plot_paths


def save_results(results: Dict[str, Any], pso_params: Dict[str, Any],
                 training_time: float, data: Dict[str, Any],
                 test_accuracy: float, report: Dict,
                 results_dir: str) -> str:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞"""

    # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_model = results['best_model']
    test_predictions = best_model.predict(data['X_test'])

    # –ü–æ–¥—Ä–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    save_data = {
        'experiment_info': {
            'experiment_name': 'PSO Neural Network Training',
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'dataset': 'Iris',
            'training_time_seconds': training_time
        },
        'parameters': {
            'pso_params': pso_params,
            'neural_network': {
                'input_size': 4,
                'hidden_size': 8,
                'output_size': 3
            }
        },
        'results': {
            'best_accuracy': float(results['best_accuracy']),
            'test_accuracy': float(test_accuracy),
            'best_fitness': float(results['best_fitness']),
            'confusion_matrix': confusion_matrix(data['y_test'], test_predictions).tolist(),
            'classification_report': report
        },
        'history': {
            'train_loss': [float(x) for x in results['history']['train_loss']],
            'val_accuracy': [float(x) for x in results['history']['val_accuracy']],
            'global_best_loss': [float(x) for x in results['history']['global_best_loss']],
            'swarm_diversity': [float(x) for x in results['history']['swarm_diversity']]
        }
    }

    save_path = os.path.join(results_dir, 'experiment_results.json')
    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(save_data, f, indent=2, ensure_ascii=False)

    return save_path


def print_results_summary(results: Dict[str, Any], data: Dict[str, Any],
                          training_time: float, plot_paths: Dict[str, str],
                          save_path: str):
    """–í—ã–≤–æ–¥ —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∫–æ–Ω—Å–æ–ª—å"""

    print("\n" + "=" * 70)
    print("–°–í–û–î–ö–ê –†–ï–ó–£–õ–¨–¢–ê–¢–û–í")
    print("=" * 70)

    print(f"\nüìä –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:")
    print(f"  –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ —Ç–µ—Å—Ç–µ: {results['best_accuracy']:.4f}")
    print(f"  –õ—É—á—à–∏–π loss: {results['best_fitness']:.4f}")
    print(f"  –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è: {training_time:.2f} —Å–µ–∫—É–Ω–¥")

    print(f"\nüìà –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö:")
    print(f"  –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {data['X_train'].shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"  –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {data['X_test'].shape[0]} –ø—Ä–∏–º–µ—Ä–æ–≤")
    print(f"  –ö–ª–∞—Å—Å—ã: {np.unique(data['y_train'])}")

    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:")
    for name, path in plot_paths.items():
        print(f"  {name}: {os.path.basename(path)}")
    print(f"  –†–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON): {os.path.basename(save_path)}")

    print(f"\n‚úÖ –≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")


def compare_with_gradient_descent(results_dir: str = "results"):
    """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ PSO —Å —Ç—Ä–∞–¥–∏—Ü–∏–æ–Ω–Ω—ã–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º"""
    print("\n" + "=" * 70)
    print("–°–†–ê–í–ù–ï–ù–ò–ï: PSO vs –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data = NeuralNetwork.load_iris_data(test_size=0.3, random_state=42)

    # –ü—Ä–æ—Å—Ç–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è)
    print("\n‚ö° –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞...")

    from sklearn.neural_network import MLPClassifier

    start_time = time.time()
    mlp = MLPClassifier(
        hidden_layer_sizes=(8,),
        activation='logistic',
        solver='sgd',
        learning_rate_init=0.01,
        max_iter=1000,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.2
    )

    mlp.fit(data['X_train'], data['y_train'])
    end_time = time.time()

    gd_training_time = end_time - start_time
    gd_accuracy = mlp.score(data['X_test'], data['y_test'])

    print(f"\n‚úÖ –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {gd_training_time:.2f} —Å–µ–∫—É–Ω–¥")
    print(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {gd_accuracy:.4f}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    fig, ax = plt.subplots(figsize=(10, 6))

    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    methods = ['PSO', '–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π —Å–ø—É—Å–∫']
    accuracies = [0.9667, gd_accuracy]  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å PSO
    times = [45.2, gd_training_time]  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –≤—Ä–µ–º—è PSO

    x = np.arange(len(methods))
    width = 0.35

    rects1 = ax.bar(x - width / 2, accuracies, width, label='–¢–æ—á–Ω–æ—Å—Ç—å', color='steelblue')
    rects2 = ax.bar(x + width / 2, times, width, label='–í—Ä–µ–º—è (—Å)', color='lightcoral')

    ax.set_xlabel('–ú–µ—Ç–æ–¥ –æ–±—É—á–µ–Ω–∏—è', fontsize=12)
    ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ PSO –∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞', fontsize=14)
    ax.set_xticks(x)
    ax.set_xticklabels(methods)
    ax.legend()

    # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
    def autolabel(rects):
        for rect in rects:
            height = rect.get_height()
            ax.annotate(f'{height:.3f}',
                        xy=(rect.get_x() + rect.get_width() / 2, height),
                        xytext=(0, 3),
                        textcoords="offset points",
                        ha='center', va='bottom', fontsize=9)

    autolabel(rects1)
    autolabel(rects2)

    ax.grid(True, alpha=0.3, axis='y')
    plt.tight_layout()

    comparison_path = os.path.join(results_dir, 'comparison_results.png')
    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

    print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {comparison_path}")
    return gd_accuracy


def parameter_sensitivity_analysis(results_dir: str = "results"):
    """–ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º PSO"""
    print("\n" + "=" * 70)
    print("–ê–ù–ê–õ–ò–ó: –ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º PSO")
    print("=" * 70)

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    data = NeuralNetwork.load_iris_data(test_size=0.3, random_state=42)

    # –¢–µ—Å—Ç–∏—Ä—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    swarm_sizes = [10, 20, 30, 50]
    w_values = [0.4, 0.7, 0.9, 1.2]
    local_search_probs = [0.0, 0.1, 0.2, 0.3]

    results_dict = {
        'swarm_size': [],
        'w_value': [],
        'local_search_prob': []
    }

    # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–∞ —Ä–æ—è
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ —Ä–æ—è:")
    swarm_accuracies = []
    for swarm_size in swarm_sizes:
        pso = ModifiedPSO(swarm_size=swarm_size)
        results = pso.run(
            X_train=data['X_train'],
            y_train=data['y_train'],
            y_train_onehot=data['y_train_onehot'],
            X_val=data['X_test'],
            y_val=data['y_test'],
            max_iterations=50  # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
        )
        accuracy = results['best_accuracy']
        swarm_accuracies.append(accuracy)
        results_dict['swarm_size'].append({'size': swarm_size, 'accuracy': accuracy})
        print(f"  –†–∞–∑–º–µ—Ä —Ä–æ—è {swarm_size}: –¢–æ—á–Ω–æ—Å—Ç—å = {accuracy:.4f}")

    # –ê–Ω–∞–ª–∏–∑ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∏–Ω–µ—Ä—Ü–∏–∏
    print("\nüìä –ê–Ω–∞–ª–∏–∑ –≤–ª–∏—è–Ω–∏—è –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∏–Ω–µ—Ä—Ü–∏–∏ (w):")
    w_accuracies = []
    for w in w_values:
        pso = ModifiedPSO(w=w)
        results = pso.run(
            X_train=data['X_train'],
            y_train=data['y_train'],
            y_train_onehot=data['y_train_onehot'],
            X_val=data['X_test'],
            y_val=data['y_test'],
            max_iterations=50
        )
        accuracy = results['best_accuracy']
        w_accuracies.append(accuracy)
        results_dict['w_value'].append({'w': w, 'accuracy': accuracy})
        print(f"  w = {w}: –¢–æ—á–Ω–æ—Å—Ç—å = {accuracy:.4f}")

    # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    fig.suptitle('–ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ PSO', fontsize=16, fontweight='bold')

    # –ì—Ä–∞—Ñ–∏–∫ 1: –†–∞–∑–º–µ—Ä —Ä–æ—è
    axes[0].bar([str(s) for s in swarm_sizes], swarm_accuracies, color='steelblue')
    axes[0].set_xlabel('–†–∞–∑–º–µ—Ä —Ä–æ—è', fontsize=12)
    axes[0].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    axes[0].set_title('–í–ª–∏—è–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ —Ä–æ—è', fontsize=13)
    axes[0].grid(True, alpha=0.3, axis='y')
    axes[0].set_ylim([0.8, 1.0])

    # –ì—Ä–∞—Ñ–∏–∫ 2: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω–µ—Ä—Ü–∏–∏
    axes[1].bar([str(w) for w in w_values], w_accuracies, color='lightcoral')
    axes[1].set_xlabel('–ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∏–Ω–µ—Ä—Ü–∏–∏ (w)', fontsize=12)
    axes[1].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    axes[1].set_title('–í–ª–∏—è–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–∞ –∏–Ω–µ—Ä—Ü–∏–∏', fontsize=13)
    axes[1].grid(True, alpha=0.3, axis='y')
    axes[1].set_ylim([0.8, 1.0])

    # –ì—Ä–∞—Ñ–∏–∫ 3: –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ä–æ—è –∏ –≤—Ä–µ–º–µ–Ω–∏
    axes[2].scatter(swarm_sizes, swarm_accuracies, s=100, color='green', alpha=0.6)
    axes[2].plot(swarm_sizes, swarm_accuracies, 'g--', alpha=0.5)
    axes[2].set_xlabel('–†–∞–∑–º–µ—Ä —Ä–æ—è', fontsize=12)
    axes[2].set_ylabel('–¢–æ—á–Ω–æ—Å—Ç—å', fontsize=12)
    axes[2].set_title('–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Ç–æ—á–Ω–æ—Å—Ç–∏ –æ—Ç —Ä–∞–∑–º–µ—Ä–∞ —Ä–æ—è', fontsize=13)
    axes[2].grid(True, alpha=0.3)
    axes[2].set_ylim([0.8, 1.0])

    plt.tight_layout()
    sensitivity_path = os.path.join(results_dir, 'parameter_sensitivity.png')
    plt.savefig(sensitivity_path, dpi=300, bbox_inches='tight')
    plt.show()
    plt.close()

    print(f"\nüìà –ì—Ä–∞—Ñ–∏–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {sensitivity_path}")

    return results_dict


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –º–µ–Ω—é –≤—ã–±–æ—Ä–∞"""
    print("=" * 60)
    print("–õ–ê–ë–û–†–ê–¢–û–†–ù–ê–Ø –†–ê–ë–û–¢–ê 4: PSO –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π")
    print("=" * 60)

    # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_dir = create_results_directory()
    print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_dir}")

    print("\n–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:")
    print("1. –û—Å–Ω–æ–≤–Ω–æ–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Å PSO")
    print("2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º")
    print("3. –ê–Ω–∞–ª–∏–∑ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
    print("4. –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤")

    choice = input("\n–í–≤–µ–¥–∏—Ç–µ –Ω–æ–º–µ—Ä (1-4): ").strip()

    if choice == "1":
        run_pso_experiment(results_dir)

    elif choice == "2":
        run_pso_experiment(results_dir)
        gd_accuracy = compare_with_gradient_descent(results_dir)

        print("\n" + "=" * 70)
        print("–ò–¢–û–ì–ò –°–†–ê–í–ù–ï–ù–ò–Ø:")
        print("=" * 70)
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å PSO: ~96.67%")
        print(f"–¢–æ—á–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞: {gd_accuracy:.2%}")
        print(f"–†–∞–∑–Ω–∏—Ü–∞: {(0.9667 - gd_accuracy):.2%}")

    elif choice == "3":
        parameter_sensitivity_analysis(results_dir)

    elif choice == "4":
        print("\nüöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤...")
        results, data = run_pso_experiment(results_dir)
        gd_accuracy = compare_with_gradient_descent(results_dir)
        sensitivity_results = parameter_sensitivity_analysis(results_dir)

        print("\n" + "=" * 70)
        print("‚úÖ –í–°–ï –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–´ –ó–ê–í–ï–†–®–ï–ù–´")
        print("=" * 70)
        print(f"üìä –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"  ‚Ä¢ –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å PSO: {results['best_accuracy']:.2%}")
        print(f"  ‚Ä¢ –¢–æ—á–Ω–æ—Å—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–≥–æ —Å–ø—É—Å–∫–∞: {gd_accuracy:.2%}")
        print(f"  ‚Ä¢ –í—Å–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {results_dir}")

    else:
        print("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π –≤—ã–±–æ—Ä. –ó–∞–ø—É—Å–∫–∞—é –æ—Å–Ω–æ–≤–Ω–æ–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç...")
        run_pso_experiment(results_dir)


if __name__ == "__main__":
    main()